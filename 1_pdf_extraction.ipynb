{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91eedf66",
   "metadata": {},
   "source": [
    "# Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afd0efda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "## Configuration\n",
    "\n",
    "BASE_PATH = \"C:/CSR_Report\"  # Change this to your actual path\n",
    "\n",
    "# Companies and years\n",
    "COMPANIES = [\"Danone\", \"Indofood\", \"Mayora\", \"Ultra_jaya\", \"Unilever\"]\n",
    "YEARS = [2019, 2020, 2021, 2022, 2023, 2024]\n",
    "\n",
    "# Output file\n",
    "OUTPUT_FILE = \"extracted_csr_data.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a450994",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ebc366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extract text from PDF file using PyMuPDF\n",
    "    Returns: dict with text and page count\n",
    "    \"\"\"\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        text = \"\"\n",
    "        page_texts = []\n",
    "        \n",
    "        # Extract text from each page\n",
    "        for page_num, page in enumerate(doc, start=1):\n",
    "            page_text = page.get_text()\n",
    "            page_texts.append({\n",
    "                \"page_number\": page_num,\n",
    "                \"text\": page_text\n",
    "            })\n",
    "            text += f\"\\n--- Page {page_num} ---\\n{page_text}\"\n",
    "        \n",
    "        doc.close()\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"full_text\": text,\n",
    "            \"page_texts\": page_texts,\n",
    "            \"page_count\": len(page_texts),\n",
    "            \"file_size\": os.path.getsize(pdf_path)\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"success\": False,\n",
    "            \"error\": str(e),\n",
    "            \"full_text\": \"\",\n",
    "            \"page_texts\": [],\n",
    "            \"page_count\": 0\n",
    "        }\n",
    "\n",
    "# %%\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Basic text cleaning\n",
    "    \"\"\"\n",
    "    # Remove excessive whitespace\n",
    "    text = \" \".join(text.split())\n",
    "    \n",
    "    # Remove excessive newlines (keep some structure)\n",
    "    text = \"\\n\".join([line.strip() for line in text.split(\"\\n\") if line.strip()])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b46022c",
   "metadata": {},
   "source": [
    "## Process All PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89e51ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_pdfs():\n",
    "    \"\"\"\n",
    "    Process all 25 PDFs and extract text with metadata\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    stats = {\n",
    "        \"total_files\": 0,\n",
    "        \"successful\": 0,\n",
    "        \"failed\": 0,\n",
    "        \"total_pages\": 0\n",
    "    }\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"Starting PDF Extraction Process\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for company in COMPANIES:\n",
    "        for year in YEARS:\n",
    "            # Construct file path\n",
    "            pdf_path = os.path.join(BASE_PATH, company, f\"CSR_{year}.pdf\")\n",
    "            \n",
    "            stats[\"total_files\"] += 1\n",
    "            \n",
    "            # Check if file exists\n",
    "            if not os.path.exists(pdf_path):\n",
    "                print(f\"‚ö†Ô∏è  NOT FOUND: {company} - {year}\")\n",
    "                stats[\"failed\"] += 1\n",
    "                continue\n",
    "            \n",
    "            print(f\"\\nüìÑ Processing: {company} - {year}\")\n",
    "            print(f\"   Path: {pdf_path}\")\n",
    "            \n",
    "            # Extract text\n",
    "            result = extract_text_from_pdf(pdf_path)\n",
    "            \n",
    "            if result[\"success\"]:\n",
    "                # Clean the text\n",
    "                cleaned_text = clean_text(result[\"full_text\"])\n",
    "                \n",
    "                # Create document with metadata\n",
    "                document = {\n",
    "                    \"company\": company,\n",
    "                    \"year\": year,\n",
    "                    \"source_file\": pdf_path,\n",
    "                    \"filename\": f\"CSR_{year}.pdf\",\n",
    "                    \"extracted_at\": datetime.now().isoformat(),\n",
    "                    \"page_count\": result[\"page_count\"],\n",
    "                    \"file_size_bytes\": result[\"file_size\"],\n",
    "                    \"text\": cleaned_text,\n",
    "                    \"page_texts\": result[\"page_texts\"]  # Keep individual pages for reference\n",
    "                }\n",
    "                \n",
    "                all_data.append(document)\n",
    "                stats[\"successful\"] += 1\n",
    "                stats[\"total_pages\"] += result[\"page_count\"]\n",
    "                \n",
    "                print(f\"   ‚úÖ Success! Pages: {result['page_count']}, Size: {result['file_size']/1024:.1f} KB\")\n",
    "                print(f\"   Text length: {len(cleaned_text):,} characters\")\n",
    "            else:\n",
    "                print(f\"   ‚ùå Failed: {result['error']}\")\n",
    "                stats[\"failed\"] += 1\n",
    "    \n",
    "    return all_data, stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7458e7c",
   "metadata": {},
   "source": [
    "## Run Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceecd9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Starting PDF Extraction Process\n",
      "============================================================\n",
      "\n",
      "üìÑ Processing: Danone - 2019\n",
      "   Path: C:/CSR_Report\\Danone\\CSR_2019.pdf\n",
      "   ‚úÖ Success! Pages: 54, Size: 30149.1 KB\n",
      "   Text length: 75,916 characters\n",
      "\n",
      "üìÑ Processing: Danone - 2020\n",
      "   Path: C:/CSR_Report\\Danone\\CSR_2020.pdf\n",
      "   ‚úÖ Success! Pages: 54, Size: 30149.1 KB\n",
      "   Text length: 75,916 characters\n",
      "\n",
      "üìÑ Processing: Danone - 2021\n",
      "   Path: C:/CSR_Report\\Danone\\CSR_2021.pdf\n",
      "   ‚úÖ Success! Pages: 30, Size: 1764.4 KB\n",
      "   Text length: 75,717 characters\n",
      "\n",
      "üìÑ Processing: Danone - 2022\n",
      "   Path: C:/CSR_Report\\Danone\\CSR_2022.pdf\n",
      "   ‚úÖ Success! Pages: 30, Size: 1764.4 KB\n",
      "   Text length: 75,717 characters\n",
      "‚ö†Ô∏è  NOT FOUND: Danone - 2023\n",
      "\n",
      "üìÑ Processing: Danone - 2024\n",
      "   Path: C:/CSR_Report\\Danone\\CSR_2024.pdf\n",
      "   ‚úÖ Success! Pages: 48, Size: 1424.4 KB\n",
      "   Text length: 135,522 characters\n",
      "‚ö†Ô∏è  NOT FOUND: Indofood - 2019\n",
      "\n",
      "üìÑ Processing: Indofood - 2020\n",
      "   Path: C:/CSR_Report\\Indofood\\CSR_2020.pdf\n",
      "   ‚úÖ Success! Pages: 31, Size: 555.5 KB\n",
      "   Text length: 107,239 characters\n",
      "\n",
      "üìÑ Processing: Indofood - 2021\n",
      "   Path: C:/CSR_Report\\Indofood\\CSR_2021.pdf\n",
      "   ‚úÖ Success! Pages: 82, Size: 3075.2 KB\n",
      "   Text length: 215,448 characters\n",
      "\n",
      "üìÑ Processing: Indofood - 2022\n",
      "   Path: C:/CSR_Report\\Indofood\\CSR_2022.pdf\n",
      "   ‚úÖ Success! Pages: 91, Size: 3337.1 KB\n",
      "   Text length: 272,688 characters\n",
      "\n",
      "üìÑ Processing: Indofood - 2023\n",
      "   Path: C:/CSR_Report\\Indofood\\CSR_2023.pdf\n",
      "   ‚úÖ Success! Pages: 115, Size: 4168.4 KB\n",
      "   Text length: 334,431 characters\n",
      "\n",
      "üìÑ Processing: Indofood - 2024\n",
      "   Path: C:/CSR_Report\\Indofood\\CSR_2024.pdf\n",
      "   ‚úÖ Success! Pages: 128, Size: 5465.4 KB\n",
      "   Text length: 363,712 characters\n",
      "\n",
      "üìÑ Processing: Mayora - 2019\n",
      "   Path: C:/CSR_Report\\Mayora\\CSR_2019.pdf\n",
      "   ‚úÖ Success! Pages: 3, Size: 124.8 KB\n",
      "   Text length: 13,627 characters\n",
      "\n",
      "üìÑ Processing: Mayora - 2020\n",
      "   Path: C:/CSR_Report\\Mayora\\CSR_2020.pdf\n",
      "   ‚úÖ Success! Pages: 21, Size: 278.9 KB\n",
      "   Text length: 82,823 characters\n",
      "\n",
      "üìÑ Processing: Mayora - 2021\n",
      "   Path: C:/CSR_Report\\Mayora\\CSR_2021.pdf\n",
      "   ‚úÖ Success! Pages: 29, Size: 465.0 KB\n",
      "   Text length: 103,243 characters\n",
      "‚ö†Ô∏è  NOT FOUND: Mayora - 2022\n",
      "\n",
      "üìÑ Processing: Mayora - 2023\n",
      "   Path: C:/CSR_Report\\Mayora\\CSR_2023.pdf\n",
      "   ‚úÖ Success! Pages: 54, Size: 2404.2 KB\n",
      "   Text length: 82,615 characters\n",
      "\n",
      "üìÑ Processing: Mayora - 2024\n",
      "   Path: C:/CSR_Report\\Mayora\\CSR_2024.pdf\n",
      "   ‚úÖ Success! Pages: 43, Size: 2717.1 KB\n",
      "   Text length: 114,180 characters\n",
      "‚ö†Ô∏è  NOT FOUND: Ultra_jaya - 2019\n",
      "\n",
      "üìÑ Processing: Ultra_jaya - 2020\n",
      "   Path: C:/CSR_Report\\Ultra_jaya\\CSR_2020.pdf\n",
      "   ‚úÖ Success! Pages: 4, Size: 3996.4 KB\n",
      "   Text length: 14,069 characters\n",
      "\n",
      "üìÑ Processing: Ultra_jaya - 2021\n",
      "   Path: C:/CSR_Report\\Ultra_jaya\\CSR_2021.pdf\n",
      "   ‚úÖ Success! Pages: 5, Size: 125.8 KB\n",
      "   Text length: 14,156 characters\n",
      "\n",
      "üìÑ Processing: Ultra_jaya - 2022\n",
      "   Path: C:/CSR_Report\\Ultra_jaya\\CSR_2022.pdf\n",
      "   ‚úÖ Success! Pages: 5, Size: 272.2 KB\n",
      "   Text length: 13,811 characters\n",
      "\n",
      "üìÑ Processing: Ultra_jaya - 2023\n",
      "   Path: C:/CSR_Report\\Ultra_jaya\\CSR_2023.pdf\n",
      "   ‚úÖ Success! Pages: 5, Size: 206.7 KB\n",
      "   Text length: 13,896 characters\n",
      "\n",
      "üìÑ Processing: Ultra_jaya - 2024\n",
      "   Path: C:/CSR_Report\\Ultra_jaya\\CSR_2024.pdf\n",
      "   ‚úÖ Success! Pages: 8, Size: 426.3 KB\n",
      "   Text length: 25,521 characters\n",
      "‚ö†Ô∏è  NOT FOUND: Unilever - 2019\n",
      "\n",
      "üìÑ Processing: Unilever - 2020\n",
      "   Path: C:/CSR_Report\\Unilever\\CSR_2020.pdf\n",
      "   ‚úÖ Success! Pages: 82, Size: 4017.8 KB\n",
      "   Text length: 254,034 characters\n",
      "\n",
      "üìÑ Processing: Unilever - 2021\n",
      "   Path: C:/CSR_Report\\Unilever\\CSR_2021.pdf\n",
      "   ‚úÖ Success! Pages: 115, Size: 5678.6 KB\n",
      "   Text length: 332,044 characters\n",
      "\n",
      "üìÑ Processing: Unilever - 2022\n",
      "   Path: C:/CSR_Report\\Unilever\\CSR_2022.pdf\n",
      "   ‚úÖ Success! Pages: 111, Size: 24073.0 KB\n",
      "   Text length: 362,785 characters\n",
      "\n",
      "üìÑ Processing: Unilever - 2023\n",
      "   Path: C:/CSR_Report\\Unilever\\CSR_2023.pdf\n",
      "   ‚úÖ Success! Pages: 124, Size: 14350.1 KB\n",
      "   Text length: 378,467 characters\n",
      "\n",
      "üìÑ Processing: Unilever - 2024\n",
      "   Path: C:/CSR_Report\\Unilever\\CSR_2024.pdf\n",
      "   ‚úÖ Success! Pages: 128, Size: 7278.3 KB\n",
      "   Text length: 388,322 characters\n"
     ]
    }
   ],
   "source": [
    "# Run the extraction process\n",
    "extracted_data, statistics = process_all_pdfs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c2c10c",
   "metadata": {},
   "source": [
    "## Display Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "051a5b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXTRACTION COMPLETE - STATISTICS\n",
      "============================================================\n",
      "Total files attempted: 30\n",
      "Successfully extracted: 25\n",
      "Failed: 5\n",
      "Total pages processed: 1400\n",
      "Average pages per document: 56.0\n",
      "\n",
      "üìä Breakdown by Company:\n",
      "   Danone: 5 reports, 216 total pages\n",
      "   Indofood: 5 reports, 447 total pages\n",
      "   Mayora: 5 reports, 150 total pages\n",
      "   Ultra_jaya: 5 reports, 27 total pages\n",
      "   Unilever: 5 reports, 560 total pages\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXTRACTION COMPLETE - STATISTICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total files attempted: {statistics['total_files']}\")\n",
    "print(f\"Successfully extracted: {statistics['successful']}\")\n",
    "print(f\"Failed: {statistics['failed']}\")\n",
    "print(f\"Total pages processed: {statistics['total_pages']}\")\n",
    "print(f\"Average pages per document: {statistics['total_pages']/max(statistics['successful'], 1):.1f}\")\n",
    "\n",
    "# Show breakdown by company\n",
    "print(\"\\nüìä Breakdown by Company:\")\n",
    "company_stats = {}\n",
    "for doc in extracted_data:\n",
    "    company = doc[\"company\"]\n",
    "    if company not in company_stats:\n",
    "        company_stats[company] = {\"count\": 0, \"pages\": 0}\n",
    "    company_stats[company][\"count\"] += 1\n",
    "    company_stats[company][\"pages\"] += doc[\"page_count\"]\n",
    "\n",
    "for company, stats in sorted(company_stats.items()):\n",
    "    print(f\"   {company}: {stats['count']} reports, {stats['pages']} total pages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363ea140",
   "metadata": {},
   "source": [
    "## Save to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8070c1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Data saved to: extracted_csr_data.json\n",
      "   File size: 7.79 MB\n"
     ]
    }
   ],
   "source": [
    "# Save extracted data\n",
    "with open(OUTPUT_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(extracted_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\nüíæ Data saved to: {OUTPUT_FILE}\")\n",
    "print(f\"   File size: {os.path.getsize(OUTPUT_FILE)/1024/1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bf37d4",
   "metadata": {},
   "source": [
    "## Quick Preview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70368534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SAMPLE EXTRACTED TEXT\n",
      "============================================================\n",
      "Company: Danone\n",
      "Year: 2019\n",
      "Pages: 54\n",
      "\n",
      "First 500 characters:\n",
      "------------------------------------------------------------\n",
      "--- Page 1 --- Melestarikan Kebaikan Lingkungan Laporan Keberlanjutan 2020 PT Tirta Investama (Danone-AQUA) 28 --- Page 2 --- Komitmen Danone-AQUA terhadap pelestarian lingkungan tercermin dalam setiap langkah operasi kami. Perusahaan menaruh perhatian tinggi terhadap upaya kami dalam meminimalkan risiko dan dampak operasi terhadap lingkungan melalui penggunaan energi yang bertanggung jawab, pemanfaatan air secara lestari hingga pengurangan limbah dan emisi. Perumusan dan implementasi kebijakan \n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Show a sample of extracted text\n",
    "if extracted_data:\n",
    "    sample = extracted_data[0]\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"SAMPLE EXTRACTED TEXT\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Company: {sample['company']}\")\n",
    "    print(f\"Year: {sample['year']}\")\n",
    "    print(f\"Pages: {sample['page_count']}\")\n",
    "    print(f\"\\nFirst 500 characters:\")\n",
    "    print(\"-\" * 60)\n",
    "    print(sample['text'][:500])\n",
    "    print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea681c7a",
   "metadata": {},
   "source": [
    "## Verify Data Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2a0f3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATA QUALITY CHECKS\n",
      "============================================================\n",
      "\n",
      "‚úÖ All documents look good!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATA QUALITY CHECKS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "issues = []\n",
    "\n",
    "for doc in extracted_data:\n",
    "    # Check for very short documents (might indicate extraction failure)\n",
    "    if len(doc['text']) < 1000:\n",
    "        issues.append(f\"‚ö†Ô∏è  {doc['company']} {doc['year']}: Very short text ({len(doc['text'])} chars)\")\n",
    "    \n",
    "    # Check for documents with very few pages\n",
    "    if doc['page_count'] < 3:\n",
    "        issues.append(f\"‚ö†Ô∏è  {doc['company']} {doc['year']}: Only {doc['page_count']} pages\")\n",
    "\n",
    "if issues:\n",
    "    print(\"\\n‚ö†Ô∏è  Potential Issues Found:\")\n",
    "    for issue in issues:\n",
    "        print(f\"   {issue}\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ All documents look good!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2515c388",
   "metadata": {},
   "source": [
    "## Next Steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06376ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "‚úÖ STEP 1 COMPLETE!\n",
      "============================================================\n",
      "\n",
      "Next: Open 02_chunking_and_embeddings.ipynb\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ STEP 1 COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nNext: Open 02_chunking_and_embeddings.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
